{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heartbeat Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityakulkarni0910/Heartbeat_classification/blob/main/Heartbeat_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RNsCJu0qkpg",
        "outputId": "08aa085a-fac1-4472-870b-7656baeaf6aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r716L6ugrz-q"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import torchtext.data as ttd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsIvtU_Qr0GC"
      },
      "source": [
        "folder = Path('/content/drive/My Drive/Study/DL/Assignment & HW/HW5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GowTZw2_GNEA"
      },
      "source": [
        "#Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74QjFe0Vase"
      },
      "source": [
        "##Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uDsH76Ar0Qx"
      },
      "source": [
        "data = pd.read_csv(folder / 'hearbeat_classification_data.csv', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKnT5udLr0VU",
        "outputId": "ff6affdb-bd51-4970-b9a9-75b36f144d2c"
      },
      "source": [
        "data.describe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of       att1@NUMERIC  att2@NUMERIC  ...  att140@NUMERIC  target\n",
              "0         1.469756     -1.048520  ...       -1.039932       1\n",
              "1        -1.998602     -3.770552  ...        0.799517       1\n",
              "2        -1.187772     -3.365038  ...       -0.824489       1\n",
              "3         0.604969     -1.671363  ...        0.023843       1\n",
              "4        -1.197203     -3.270123  ...        1.734676       1\n",
              "...            ...           ...  ...             ...     ...\n",
              "4995     -0.248881     -1.346474  ...       -0.378163       0\n",
              "4996     -0.287286     -1.199089  ...        0.075742       0\n",
              "4997     -1.032096     -2.811901  ...        0.750669       1\n",
              "4998     -1.592541     -2.461370  ...        0.354016       0\n",
              "4999     -1.945586     -3.840519  ...       -1.366044       1\n",
              "\n",
              "[5000 rows x 141 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecwt5RmCr0aM",
        "outputId": "5b69ee3d-e257-457d-ebad-e3d58206089c"
      },
      "source": [
        "data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2919\n",
              "0    2081\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK_MYV9c8nsh"
      },
      "source": [
        "corpus = (data.drop('target',axis=1)).values\n",
        "labels = data['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7DCm2E8Stt"
      },
      "source": [
        "# separate into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    corpus,  # predictors\n",
        "    labels,  # target\n",
        "    test_size=0.2,  # percentage of obs in test set\n",
        "    random_state=0)  # seed to ensure reproducibility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr-o8gFh8ly0"
      },
      "source": [
        "X_train = torch.tensor(X_train).float()\n",
        "y_train=torch.tensor(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M4CmSwU9Qjo"
      },
      "source": [
        "X_test = torch.tensor(X_test).float()\n",
        "y_test=torch.tensor(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xleRCzp99Taf"
      },
      "source": [
        "from torch.utils import data\n",
        "train_dataset = data.TensorDataset(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt0Ldzj29VpD"
      },
      "source": [
        "test_dataset = data.TensorDataset(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCDTUUhQ9Yn4"
      },
      "source": [
        "batch_size=16\n",
        "train_loader= torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_f-vthQ9Yjb"
      },
      "source": [
        "test_loader= torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNLCJFa_9Ydm",
        "outputId": "bbe8ca22-9782-4970-f8ef-e77630141bbb"
      },
      "source": [
        "# Check out what the data loader does\n",
        "# makes the data of shape (batch size, color, height, width)\n",
        "for inputs, targets in train_loader:\n",
        "  print(\"input shape:\", inputs.shape, \"output shape:\", targets.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape: torch.Size([16, 140]) output shape: torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaGOZ71sVijS"
      },
      "source": [
        "##1.1 Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5bM9rW80jY_"
      },
      "source": [
        "### Define simple RNN\n",
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.D = n_inputs\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "\n",
        "    # note: batch_first=True\n",
        "    # applies the convention that our data will be of shape:\n",
        "    # (num_samples, sequence_length, num_features)\n",
        "    # rather than:\n",
        "    # (sequence_length, num_samples, num_features)\n",
        "    self.rnn = nn.RNN(\n",
        "        input_size=self.D,\n",
        "        hidden_size=self.M,\n",
        "        num_layers=self.L,\n",
        "        nonlinearity='relu',\n",
        "        batch_first=True)\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    # initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    # get RNN unit output\n",
        "    # out is of size (N, sequence_length, M)\n",
        "    # 2nd return value is hidden states at each hidden layer\n",
        "    # we don't need those now\n",
        "    out, _ = self.rnn(X, h0)\n",
        "\n",
        "    # we only want h(T) at the final time step\n",
        "    # N x M -> N x K\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWKYqyL5j1DO",
        "outputId": "b6b930d8-9597-4266-f759-73523d4df098"
      },
      "source": [
        "# upload model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEyuSMCt0jyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fd938a-9245-49a5-82e3-f1b32fdb901e"
      },
      "source": [
        "model_1 = SimpleRNN(n_inputs=1, n_hidden=10, n_rnnlayers=1, n_outputs=2)\n",
        "model_1.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleRNN(\n",
              "  (rnn): RNN(1, 10, batch_first=True)\n",
              "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fVNzx6pHcCD"
      },
      "source": [
        "#In the training loop below, I changed the input dimensions \"input.view(-1,140,1)\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Zj8bJh0j3j",
        "outputId": "916302d6-d88a-4382-f5a5-2836e6324cf8"
      },
      "source": [
        "epochs =5\n",
        "lr= 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_1.parameters(), lr)\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "test_losses= np.zeros(epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model_1.train()\n",
        "  for input,targets in train_loader:\n",
        "\n",
        "    input = input.to(device)\n",
        "    targets= targets.to(device)\n",
        " \n",
        "    input= (input.view(-1,140,1)) #\n",
        "\n",
        "    # forward pass\n",
        "    output= model_1(input)\n",
        "\n",
        "    loss=criterion(output,targets)\n",
        "    \n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  test_loss=[]\n",
        "  model_1.eval()\n",
        "  with torch.no_grad():\n",
        "    for input,targets in test_loader:\n",
        "      # load input and output to GPU\n",
        "      input = (input.float()).to(device)\n",
        "      targets= targets.to(device)\n",
        "      \n",
        "      # reshape the input\n",
        "      input = input.view(-1,140,1) #\n",
        "      # forward pass\n",
        "      output= model_1(input)\n",
        "      loss=criterion(output,targets)\n",
        "      test_loss.append(loss.item())\n",
        "\n",
        "    test_loss=np.mean(test_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  test_losses[epoch]= test_loss\n",
        "\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Test Loss: {test_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Train Loss: 0.5440    Test Loss: 0.3328, Duration: 0:00:04.145648\n",
            "Epoch 2/5, Train Loss: 0.2526    Test Loss: 0.2057, Duration: 0:00:03.849462\n",
            "Epoch 3/5, Train Loss: 0.2098    Test Loss: 0.1854, Duration: 0:00:04.321926\n",
            "Epoch 4/5, Train Loss: 0.2005    Test Loss: 0.1788, Duration: 0:00:04.277346\n",
            "Epoch 5/5, Train Loss: 0.1972    Test Loss: 0.1740, Duration: 0:00:03.997787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETlGCC9y0j82"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get train/test accuracy and print accuracy\n",
        "def get_accuracy(train_loader, test_loader, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct_train=correct_test=0\n",
        "    total_train=total_test=0\n",
        "    \n",
        "    for input, targets in train_loader:\n",
        "      input= input.to(device)\n",
        "      targets= targets.to(device)\n",
        "      input = input.view(-1,140,1) #\n",
        "      output=model(input)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct_train+= (targets==indices).sum().item()\n",
        "      total_train += targets.shape[0]\n",
        "    \n",
        "    train_acc= correct_train/total_train\n",
        "\n",
        "    for input, targets in test_loader:\n",
        "      input= input.to(device)\n",
        "      targets= targets.to(device)\n",
        "      input = input.view(-1,140,1) #\n",
        "      output=model(input)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct_test+= (targets==indices).sum().item()\n",
        "      total_test += targets.shape[0]\n",
        "    \n",
        "    test_acc= correct_test/total_test\n",
        "    return train_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4oULSttiytQ",
        "outputId": "0b1c25f0-948b-4ae4-e749-d61f286e4a09"
      },
      "source": [
        "train_acc, test_acc = get_accuracy(train_loader, test_loader, model_1)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9357,\t Test acc: 0.9470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GVRC-cXb-GI"
      },
      "source": [
        "##1.2 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Bi9jJBb-GI"
      },
      "source": [
        "### Define simple RNN\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.D = n_inputs\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "\n",
        "    # note: batch_first=True\n",
        "    # applies the convention that our data will be of shape:\n",
        "    # (num_samples, sequence_length, num_features)\n",
        "    # rather than:\n",
        "    # (sequence_length, num_samples, num_features)\n",
        "    self.rnn = nn.LSTM(\n",
        "        input_size=self.D,\n",
        "        hidden_size=self.M,\n",
        "        num_layers=self.L,\n",
        " #       nonlinearity='relu',\n",
        "        batch_first=True)\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    # initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    # get RNN unit output\n",
        "    # out is of size (N, sequence_length, M)\n",
        "    # 2nd return value is hidden states at each hidden layer\n",
        "    # we don't need those now\n",
        "    out, _ = self.rnn(X, (h0, c0))\n",
        "\n",
        "    # we only want h(T) at the final time step\n",
        "    # N x M -> N x K\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYsZhf--b-GI",
        "outputId": "d904d741-9458-4f8f-c4cd-2b5dcd5bbcd1"
      },
      "source": [
        "# upload model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h24ScSgCb-GJ",
        "outputId": "a4e1ae14-2a0b-418c-b121-42cf134ebdf5"
      },
      "source": [
        "model_3 = LSTM(n_inputs=1, n_hidden=10, n_rnnlayers=1, n_outputs=2)\n",
        "model_3.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (rnn): LSTM(1, 10, batch_first=True)\n",
              "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPV1AvS9b-GJ"
      },
      "source": [
        "#In the training loop below, I changed the input dimensions \"input.view(-1,140,1)\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRLurE0Ob-GJ",
        "outputId": "bb58e0cb-8a8d-420e-f30d-58cd598a38b8"
      },
      "source": [
        "epochs =5\n",
        "lr= 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_3.parameters(), lr)\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "test_losses= np.zeros(epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model_3.train()\n",
        "  for input,targets in train_loader:\n",
        "\n",
        "    input = input.to(device)\n",
        "    targets= targets.to(device)\n",
        " \n",
        "    input= (input.view(-1,140,1)) #\n",
        "\n",
        "    # forward pass\n",
        "    output= model_3(input)\n",
        "\n",
        "    loss=criterion(output,targets)\n",
        "    \n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  test_loss=[]\n",
        "  model_3.eval()\n",
        "  with torch.no_grad():\n",
        "    for input,targets in test_loader:\n",
        "      # load input and output to GPU\n",
        "      input = (input.float()).to(device)\n",
        "      targets= targets.to(device)\n",
        "      \n",
        "      # reshape the input\n",
        "      input = input.view(-1,140,1) #\n",
        "      # forward pass\n",
        "      output= model_3(input)\n",
        "      loss=criterion(output,targets)\n",
        "      test_loss.append(loss.item())\n",
        "\n",
        "    test_loss=np.mean(test_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  test_losses[epoch]= test_loss\n",
        "\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Test Loss: {test_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Train Loss: 0.6679    Test Loss: 0.6324, Duration: 0:00:09.654106\n",
            "Epoch 2/5, Train Loss: 0.5961    Test Loss: 0.5483, Duration: 0:00:09.527208\n",
            "Epoch 3/5, Train Loss: 0.4932    Test Loss: 0.4280, Duration: 0:00:09.707292\n",
            "Epoch 4/5, Train Loss: 0.3692    Test Loss: 0.3115, Duration: 0:00:09.415029\n",
            "Epoch 5/5, Train Loss: 0.2843    Test Loss: 0.2548, Duration: 0:00:09.625608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFtD6x3_b-GJ"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get train/test accuracy and print accuracy\n",
        "def get_accuracy(train_loader, test_loader, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct_train=correct_test=0\n",
        "    total_train=total_test=0\n",
        "    \n",
        "    for input, targets in train_loader:\n",
        "      input= input.to(device)\n",
        "      targets= targets.to(device)\n",
        "      input = input.view(-1,140,1) #\n",
        "      output=model(input)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct_train+= (targets==indices).sum().item()\n",
        "      total_train += targets.shape[0]\n",
        "    \n",
        "    train_acc= correct_train/total_train\n",
        "\n",
        "    for input, targets in test_loader:\n",
        "      input= input.to(device)\n",
        "      targets= targets.to(device)\n",
        "      input = input.view(-1,140,1) #\n",
        "      output=model(input)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct_test+= (targets==indices).sum().item()\n",
        "      total_test += targets.shape[0]\n",
        "    \n",
        "    test_acc= correct_test/total_test\n",
        "    return train_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYPIDMzQb-GJ",
        "outputId": "383ffaf7-ee00-466d-d13b-db9155425ba1"
      },
      "source": [
        "train_acc, test_acc = get_accuracy(train_loader, test_loader, model_3)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9265,\t Test acc: 0.9320\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}